{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction, part 2\n",
    "\n",
    "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons Licence\" style=\"width=50\" src=\"https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "**Authors**: Dr Matteo Degiacomi (matteo.t.degiacomi@durham.ac.uk) and Dr Antonia Mey (antonia.mey@ed.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives**:\n",
    "* Calculating and interpreting the PCA of one or multiple molecular dynamics trajectory\n",
    "* Calculating TICA of a molecular dynamics trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter cheat sheet**:\n",
    "* to run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "* to get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab package installs\n",
    "\n",
    "This installs the necessary packages for Google Colab. Please only run these if you are using Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "!if [ -n \"$COLAB_GPU\" ]; then pip install condacolab; fi\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "import condacolab\n",
    "condacolab.check()\n",
    "!mamba install -c conda-forge mdanalysis mdanalysistests mdanalysisdata nglview scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "# enable third party jupyter widgets\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "# copy over data repository\n",
    "!if [ -n \"$COLAB_GPU\" ]; then git clone https://github.com/MDAnalysis/WorkshopMDMLEdinburgh2022.git; fi\n",
    "!if [ -n \"$COLAB_GPU\" ]; then cp -r WorkshopMDMLEdinburgh2022/ML/data .; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with this tutorial, let's importing some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nglview as nv\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulations in this tutorial are presented in: [M.T. Degiacomi (2019). Coupling Molecular Dynamics and Deep Learning to Mine Protein Conformational Space, Structure](https://doi.org/10.1016/j.str.2019.03.018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MurD is a 47-kDa ATP-driven ligase responsible for the biosynthesis of a bacterial peptidoglycan precursor (UDP-N-acetylmuramoyl-L-alanyl-D-glutamate). When bound to its ligand, UDP-N-acetylmuramoyl-L-alanyl-D-alanine, MurD is stabilized in a closed conformation (PDB: [3UAG](https://www.rcsb.org/structure/3UAG)). Here, we will load a downsampled version of an MD trajectory of this state (140 ns with a step size of 0.2 ns of backbone atoms of residues 7-436)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data/\" # this is the path where the three simulations are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_closed = mda.Universe(f'{folder}MurD_closed_backbone.pdb')\n",
    "w = nv.show_mdanalysis(universe_closed)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of UDP-N-acetylmuramoyl-L-alanyl-D-alanine, MurD takes instead an open conformation (PDB: [1E0D](https://www.rcsb.org/structure/1E0D)). Let's load an MD trajectory of this state (same atoms selection, simulation length, and step as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_open = mda.Universe(f'{folder}MurD_open_backbone.pdb')\n",
    "w = nv.show_mdanalysis(universe_open)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup of feature extraction tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Featurizer` implements different ways of extracting features from a simulation using MDAnalysis. It is implemented to ensure consistency in feature extraction across the different datasets in the remainder of this exercises. Run this cell as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDAnalysis.analysis.dihedrals import Ramachandran\n",
    "from MDAnalysis.analysis import distances\n",
    "\n",
    "class Featurizer(object):\n",
    "    \n",
    "    def __init__(self, feature):\n",
    "        '''Featurizer class for extracting MD features with MDAnalysis\n",
    "        Parameters:\n",
    "        -----------\n",
    "        feature : String\n",
    "            name of feature\n",
    "        '''\n",
    "        if feature == \"ramachandran\":\n",
    "            self.get_features = self._get_features_ramachandran\n",
    "        elif feature == \"distance matrix\":    \n",
    "            self.get_features = self._get_features_distance_matrix\n",
    "        elif feature == \"coordinates\":    \n",
    "            self.get_features = self._get_features_coordinates\n",
    "        elif feature == \"custom\":\n",
    "            self.get_features = self._get_features_custom\n",
    "        else:\n",
    "            raise Exception(\"Features extraction method %s not recognised\"%feature)\n",
    "            \n",
    "        self.feature = feature\n",
    " \n",
    "    \n",
    "    def _get_features_coordinates(self, universe):\n",
    "        '''\n",
    "        alpha carbons coordinates\n",
    "        '''\n",
    "        crds = []\n",
    "        ca = universe.select_atoms(\"name CA\")\n",
    "        for ts in universe.trajectory:\n",
    "            crds.append(ca.positions.flatten())\n",
    "\n",
    "        return np.array(crds)\n",
    "\n",
    "\n",
    "    def _get_features_ramachandran(self, universe):\n",
    "        '''\n",
    "        dihedral angles\n",
    "        '''\n",
    "        r = Ramachandran(universe.select_atoms('protein')).run()\n",
    "        r_sin = np.sin(np.deg2rad(r.angles))\n",
    "        r_cos = np.cos(np.deg2rad(r.angles))\n",
    "        \n",
    "        r_sin = r_sin.reshape((r_sin.shape[0], np.prod(r_sin.shape[1:])))\n",
    "        r_cos = r_cos.reshape((r_cos.shape[0], np.prod(r_cos.shape[1:])))\n",
    "        return np.concatenate((r_sin, r_cos), axis=1)\n",
    "        \n",
    "    \n",
    "    def _get_features_distance_matrix(self, universe):\n",
    "        '''\n",
    "        returns the distance matrix of each conformation (lower diagonal, flattened)\n",
    "        see MDAnalysis.analysis.distances.self_distance_array\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def _get_features_custom(self, universe):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparation and analysis of training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to collect features from two independent simulations of the closed and open state of MurD. Let's start by defining which kind of feature we are interested in extracting from the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = \"coordinates\"\n",
    "F = Featurizer(feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now extract the features from the simulations of closed and open state. This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from the simulations of the closed state\n",
    "feat_closed = F.get_features(universe_closed)\n",
    "print(f'closed state: {feat_closed.shape[0]} conformations, {feat_closed.shape[1]} features')\n",
    "\n",
    "# extract features from the simulation of the open state\n",
    "feat_open = F.get_features(universe_open)\n",
    "print(f'open state: {feat_open.shape[0]} conformations, {feat_open.shape[1]} features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PCA of multiple MD simulations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's project our features on a lower dimensional space using Principal Components Analysis ([PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)), c.f. our [previous notebook on dimensionality reduction](2_DR_part2.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_closed = PCA()\n",
    "pca_closed.fit(feat_closed)\n",
    "proj_closed = pca_closed.transform(feat_closed)\n",
    "\n",
    "pca_open = PCA()\n",
    "pca_open.fit(feat_open)\n",
    "proj_open = pca_open.transform(feat_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features have now been projected in their eigenspace. The first dimension in the eigenspace is the one displaying the largest variance in data (i.e. describes the largest correlated motion in our simulation), the second dimension is ortogonal to the first and describes the second largest correlated motion, and so on. Let's have a look at how much motion is captured by each of the first 20 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "xaxis = list(range(1, 21))\n",
    "ax.plot(xaxis, pca_closed.explained_variance_ratio_[:20], marker=\".\", linewidth = 0.1, color=\"dodgerblue\", label=\"closed\")\n",
    "ax.plot(xaxis, pca_open.explained_variance_ratio_[:20], marker=\".\", linewidth = 0.1, color=\"red\", label=\"open\")\n",
    "ax.set_xticks(xaxis[::2])\n",
    "ax.set_xlabel(\"eigenvector (#)\")\n",
    "ax.set_ylabel(\"explained variance\")\n",
    "ax.legend(frameon=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Compressing an MD simulation</b>\n",
    "\n",
    "Often the first few dimensions in the eigenspace of atomic coordinates can, together, capture majority of the variance in an MD simulation. How come the thousands of features describing a protein can be compressed in so few dimensions? This is because the many atoms composing a protein tend to move togeher, i.e. the data features very high correlation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a projection of the data in 2D space (the two first principac components), also reporting the percentage of variance represented by each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.scatter(proj_closed[:, 0], proj_closed[:, 1], alpha=0.2, color=\"dodgerblue\")\n",
    "ax1.set_title(\"closed\")\n",
    "ax1.set_xlabel(f'PC 1, {pca_closed.explained_variance_ratio_[0]*100:3.2f}%')\n",
    "ax1.set_ylabel(f'PC 2, {pca_closed.explained_variance_ratio_[1]*100:3.2f}%')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.scatter(proj_open[:, 0], proj_open[:, 1], alpha=0.2, color=\"red\")\n",
    "ax2.set_title(\"open\")\n",
    "ax2.set_xlabel(f'PC 1, {pca_open.explained_variance_ratio_[0]*100:3.2f}%')\n",
    "ax2.set_ylabel(f'PC 2, {pca_open.explained_variance_ratio_[1]*100:3.2f}%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue we are having, is that each dataset has been projected in its own eigenspace. In other terms, the two plots we have just produced just report on the structure of their dataset, but are not directly comparable. Do compare two simulations, we need to project them in the ***same*** eigenspace. This requires concatenating the trajectories (of course, this can only be done if the same features have been extracted from them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the two trajectories\n",
    "all_features = np.concatenate((feat_closed, feat_open))\n",
    "\n",
    "# calculate PCA and project the individual trajectories in the resulting eigenspace\n",
    "pca = PCA()\n",
    "pca.fit(all_features)\n",
    "\n",
    "proj_closed = pca.transform(feat_closed)\n",
    "proj_open = pca.transform(feat_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the PCA of our concatenated simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(proj_closed[:, 0], proj_closed[:, 1], alpha=0.2, color=\"dodgerblue\", label=\"closed\")\n",
    "ax.scatter(proj_open[:, 0], proj_open[:, 1], alpha=0.2, color=\"red\", label=\"open\")\n",
    "ax.set_xlabel(f'PC 1, {pca.explained_variance_ratio_[0]*100:3.2f}%')\n",
    "ax.set_ylabel(f'PC 2, {pca.explained_variance_ratio_[1]*100:3.2f}%')\n",
    "ax.legend(frameon=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 1.</b> What happens if you downsample one of the two simulations, before concatenating them?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 1</mark> </summary>\n",
    "\n",
    "We can create an unbalanced dataset featuring a simulation with way less conformations than the other (20 times less) as follows:\n",
    "\n",
    "```Python  \n",
    "all_features = np.concatenate((feat_closed[::20], feat_open))\n",
    "```\n",
    "\n",
    "The resulting projection into a 2D eigenspace will look different from that obtained from a balanced dataset. The simulation having the larger number of conformations will become more relevant (i.e. will \"spread more\" in the eigenspace).\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Watch out for rototranslations!</b>\n",
    "\n",
    "If the features you are extracting are affected by the specific position and orientation of the molecule in the simulation box (e.g., you are extracting atomic coordinates), it is commonplace to first align your trajectory. The PCA will otherwise identify rototranslation as more important variations than any internal motion you may be interested in. Some features are unaffected by rototranslation of the dataset (e.g. dihedral angles), in this case trajectory alignment is not necessary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 2.</b> In Section 2 we have defined the class <code>Featurizer</code>, defining different methods to extract features from an MDAnalysis Universe. The class was used in the first cell of Section 3. Run again this notebook from Section 3, setting  <code>feature_type = \"ramachandran\"</code>. What do you notice?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 3.</b> Return to Section 2 and, within the class <code>Featurizer</code>, use MDAnalysis to implement the method <code>_get_features_distance_matrix</code>, returning a flattened lower triangular distance matrix. Rerun the rest of the notebook with your new feature. If you are feeling adventurous, implement your own feature in the function <code>Featurizer._get_features_custom</code></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <mark> Answer 3</mark> </summary>\n",
    "\n",
    "The following is the method to be implemented in Featurizer.\n",
    "    \n",
    "```Python    \n",
    "def _get_features_distance_matrix(self, universe):\n",
    "    '''\n",
    "    returns distance matrix of each conformation (lower diagonal, flattened)\n",
    "    '''\n",
    "    crds = []\n",
    "    ca = universe.select_atoms(\"name CA\")\n",
    "    for ts in universe.trajectory:\n",
    "        crds.append(distances.self_distance_array(ca.positions))\n",
    "\n",
    "    return np.array(crds)\n",
    "```\n",
    "    \n",
    "As new feature, how about mesuring the angles formed by different domains? Or their relative orientation in spherical coordinates? Or selecting the distances between specific amino acid pairs, instead of using the whole distance matrix?\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. tICA of multiple MD simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same simulation datasets as before, but this time we will perform a tICA analysis. Like for the PCA, we will start by analysing the simulations separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tica.tica import tICA\n",
    "\n",
    "tic_closed = tICA()\n",
    "tic_closed.fit([feat_closed])\n",
    "tic_proj_closed = tic_closed.transform([feat_closed])[0]\n",
    "\n",
    "tic_open = tICA()\n",
    "tic_open.fit([feat_open])\n",
    "tic_proj_open = tic_open.transform([feat_open])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot 2D projections of the two simulations in their respective tIC space. Here, we will colour each datapoint as a function of its timestep (from yellow to purple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.scatter(tic_proj_closed[:, 0], tic_proj_closed[:, 1], alpha=0.2, c=range(len(tic_proj_closed)))#, color=\"dodgerblue\")\n",
    "ax1.set_title(\"closed\")\n",
    "ax1.set_xlabel(f'tIC 1')\n",
    "ax1.set_ylabel(f'tIC 2')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.scatter(tic_proj_open[:, 0], tic_proj_open[:, 1], alpha=0.2, c=range(len(tic_proj_open)))#, color=\"red\")\n",
    "ax2.set_title(\"open\");\n",
    "ax2.set_xlabel(f'tIC 1')\n",
    "ax2.set_ylabel(f'tIC 2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed when discussing PCA, two simulations can only be compared if they are projected in the same space. Let's do the same for tICA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic.fit([feat_closed, feat_open])\n",
    "tic_proj_closed2 = tic.transform([feat_closed])[0]\n",
    "tic_proj_open2 = tic.transform([feat_open])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to plot the projections of the two simulations in their shared tIC space now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(tic_proj_closed2[:, 0], tic_proj_closed2[:, 1], alpha=0.2, color=\"dodgerblue\", label=\"closed\")\n",
    "ax.scatter(tic_proj_open2[:, 0], tic_proj_open2[:, 1], alpha=0.2, color=\"red\", label=\"open\")\n",
    "ax.legend(frameon=False);\n",
    "ax.set_xlabel(f'tIC 1')\n",
    "ax.set_ylabel(f'tIC 2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 4.</b> Looking at both the projection of the two simulations in separated and shared tIC space, how does the tICA analysis differ from PCA using different input features?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Key points:</b>\n",
    "    \n",
    "- PCA identifies dominant motions in MD simulations by looking at directions of maximal variance in data\n",
    "- tICA identifies dimensions whereby the decay time of the autocorrelation function of each dimension is maximised\n",
    "- some features are position-dependent (e.g. atom coordinates), and some are not (e.g. dihedral angles)\n",
    "- if handling position-dependent features:\n",
    "    - trajectory alignment will affect what kind of motion will be identified by any dimensionality reduction technique\n",
    "    - if the trajectory is not aligned, the dominant motion identified will be most likely linked to the rigid body rototranslation of the molecule of interest\n",
    "- when the features are highly correlated, data can be efficiently compressed in a low-dimensional space with minimal information loss.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these first two notebook we have mentioned three common dimensionality reduction techniques: PCA, tICA, and t-SNE (for the latter, see [previous notebook](1_DR_part1.ipynb)). Other techniques exist though! For instance, the MurD simulations we used in this notebook have also be examined using a special type of neural network called autoencoder:\n",
    "[V.K. Ramaswamy et al. (2021). Learning protein conformational space with convolutions and latent interpolations, Physical Review X 11](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.011052)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Clustering](3_clustering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
